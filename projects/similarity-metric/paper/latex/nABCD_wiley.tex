\documentclass[AMA,Times1COL]{WileyNJDv5}

\articletype{Research Article}%

\received{Date Month Year}
\revised{Date Month Year}
\accepted{Date Month Year}
\journal{Statist.\ Med.}
\volume{00}
\copyyear{2025}
\startpage{1}

\raggedbottom

\graphicspath{{../../figures/}}

\begin{document}

\title{nABCD: A Normalized Metric for Comparing Effect Modifier Distributions in Multi-Regional Clinical Trials}

\author[1]{Author One}

\author[2]{Author Two}

\author[1]{Author Three}

\authormark{AUTHOR ONE \textsc{et al.}}
\titlemark{nABCD FOR COMPARING EFFECT MODIFIER DISTRIBUTIONS}

\address[1]{\orgdiv{Department Name}, \orgname{Institution Name}, \orgaddress{\state{State}, \country{Country}}}

\address[2]{\orgdiv{Department Name}, \orgname{Institution Name}, \orgaddress{\state{State}, \country{Country}}}

\corres{Corresponding Author, Department Name, Institution Name, Address. \email{corresponding@institution.edu}}

\abstract[Abstract]{%
\textbf{Background}: The ICH E17 guideline recommends regional pooling in multi-regional clinical trials (MRCTs) based on similarity of effect modifier (EM) distributions, but provides no specific methodology for quantifying such similarity. Existing approaches focus on location differences (standardized mean difference) or lack interpretable scales (Kolmogorov--Smirnov statistic).
\textbf{Objective}: To develop and validate a metric for estimating EM distributional differences across regions, together with a clinical calibration framework that translates those estimates into potential treatment effect heterogeneity on the outcome scale.
\textbf{Methods}: We propose the normalized Area Between Cumulative Distributions (nABCD), defined as the Wasserstein-1 distance between two distributions divided by twice the pooled interquartile range. Through its connection to the treatment effect heterogeneity bound, nABCD enables clinical calibration: the maximum potential regional treatment effect difference ($\Delta_{\max}$) is expressed as a function of nABCD, the pooled IQR, and the CATE sensitivity of the EM. Bootstrap confidence intervals quantify estimation uncertainty. We conducted simulation studies across scenarios including location shifts, scale differences, and shape differences, with sample sizes from 50 to 200 per region.
\textbf{Results}: The nABCD estimator showed bias $<0.02$ for $n \geq 100$ across non-null scenarios. Bootstrap 95\% confidence intervals achieved coverage within 0.89--0.98 for $n \geq 100$ in most scenarios. Unlike standardized mean difference, nABCD captured scale and shape differences where SMD showed no effect. Application to a diabetes MRCT demonstrated that clinical calibration with $\Delta_{\max}$ provides context-dependent interpretation: the same distributional difference carries different clinical implications depending on the EM's CATE sensitivity.
\textbf{Conclusions}: nABCD provides a validated metric for assessing EM distributional similarity in MRCTs. Through its connection to treatment effect heterogeneity bounds, nABCD translates distributional differences into potential treatment effect differences on the clinical scale, enabling context-dependent interpretation calibrated to the sensitivity of each effect modifier. We recommend $n \geq 100$ per region for reliable estimation and inference.}

\keywords{multi-regional clinical trial; ICH E17; effect modifier; Wasserstein distance; regional pooling; distributional similarity}

\jnlcitation{\cname{%
\author{Author One},
\author{Author Two}, and
\author{Author Three}}.
\ctitle{nABCD: A normalized metric for comparing effect modifier distributions in multi-regional clinical trials.} \cjournal{Statist.\ Med.} \cvol{2025;00:1--18}.}

\maketitle

\renewcommand\thefootnote{}
\footnotetext{\textbf{Abbreviations:} ABCD, area between cumulative distributions; CATE, conditional average treatment effect; CDF, cumulative distribution function; CI, confidence interval; CKD, chronic kidney disease; EM, effect modifier; EU, European Union; ICH, International Council for Harmonisation; IQR, interquartile range; KS, Kolmogorov--Smirnov; MRCT, multi-regional clinical trial; nABCD, normalized area between cumulative distributions; NMPA, National Medical Products Administration; SMD, standardized mean difference; US, United States.}

\renewcommand\thefootnote{\fnsymbol{footnote}}
\setcounter{footnote}{1}

%==============================================================================
\section{Introduction}\label{sec:intro}
%==============================================================================

\subsection{Background}\label{sec:background}

Multi-regional clinical trials (MRCTs), conducted across multiple countries or regulatory regions under a single protocol, have become the standard paradigm for global pharmaceutical development.\cite{chen2010,quan2010} This approach offers substantial benefits: accelerated timelines, broader generalizability, and earlier access to new therapies for patients worldwide. The International Council for Harmonisation (ICH) E17 guideline, adopted in 2017, established principles for planning and designing MRCTs, with a central assumption that treatment effects are generalizable across the target population.\cite{iche17}

A key strategy for addressing potential regional heterogeneity is the regional pooling approach, wherein regions with similar patient characteristics are grouped for randomization and/or analysis.\cite{iche17} The ICH E17 guideline explicitly recommends that pooling decisions be based on the similarity of effect modifier (EM) distributions:

\begin{quote}
``Regions may be pooled for randomisation and/or analysis if subjects are thought to be \textbf{similar enough} with respect to intrinsic and/or extrinsic factors relevant to the disease and/or drug under study.'' (ICH E17, Section 2.2.5)
\end{quote}

An effect modifier is a baseline patient characteristic---such as age, disease severity, or genetic marker---for which the treatment benefit differs across subgroups. For example, if younger patients respond better to treatment than older patients, age is an effect modifier. When such heterogeneity exists, even if the drug works identically at the individual level, regions with different patient compositions may observe different average treatment effects. A region with predominantly younger patients would show larger benefits than a region with predominantly older patients, not because the drug works differently, but because the patient mix differs. This fundamental relationship underscores why EM distributional similarity is critical to the validity of regional pooling.

\subsection{The Methodological Gap}\label{sec:gap}

Despite the regulatory importance of EM distributional similarity, current practice lacks a standardized quantitative methodology. The ICH E17 guideline provides no specific metric, threshold, or statistical procedure for determining when distributions are ``similar enough.'' Recent regulatory guidance has highlighted this gap. Song et al., writing from the China NMPA perspective on ICH E17 implementation, note the challenge of operationalizing pooling criteria without quantitative tools.\cite{song2025} Long et al.\ further discuss basic considerations for consistency evaluation under ICH E17.\cite{long2025}

Current approaches to assessing distributional similarity have significant limitations (Table~\ref{tab:limitations}). The standardized mean difference, while widely used for baseline covariate comparisons,\cite{austin2011} fundamentally cannot detect differences in variance or distributional shape---precisely the types of differences that may drive treatment effect heterogeneity through effect modification.

\begin{table}[ht]
\caption{Limitations of current approaches to distributional similarity assessment.\label{tab:limitations}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}ll@{}}
\toprule
\textbf{Method} & \textbf{Limitation} \\
\midrule
Visual inspection & Subjective, not reproducible \\
Standardized mean difference (SMD) & Captures only location, ignores scale and shape \\
Kolmogorov--Smirnov statistic & No interpretable scale for decision-making \\
\bottomrule
\end{tabular*}
\end{table}

\subsection{Objectives and Contribution}\label{sec:objectives}

This paper addresses the methodological gap by proposing the \textbf{normalized Area Between Cumulative Distributions (nABCD)}, a metric for comparing EM distributions across regions, together with a clinical calibration framework that translates distributional differences into potential treatment effect heterogeneity on the outcome scale. Our specific research question is:

\begin{quote}
\textbf{How can we estimate distributional similarity between regions in a scale-free manner, and translate that estimate into clinically interpretable information about potential treatment effect heterogeneity?}
\end{quote}

The emphasis is on \textbf{estimation and clinical interpretation}, not hypothesis testing. We seek to provide regulatory scientists with quantitative tools that inform deliberation, not with binary accept/reject rules. This design philosophy reflects the ICH E17 principle that pooling decisions require contextual judgment rather than mechanical application of thresholds.

The nABCD metric measures the total area between two cumulative distribution functions, normalized by the pooled interquartile range to achieve scale-free interpretation. The framework offers four contributions:

\begin{enumerate}[1.]
\item \textbf{Full distributional comparison}: The Wasserstein-1 distance captures differences in location, scale, and shape simultaneously.\cite{panaretos2019}
\item \textbf{Scale-free estimation}: Normalization by IQR yields a unitless measure, enabling comparisons across EMs measured on different scales. Bootstrap confidence intervals quantify estimation uncertainty.
\item \textbf{Clinical calibration}: Through the heterogeneity bound (Proposition~\ref{prop:heterogeneity}), nABCD estimates can be translated into potential treatment effect differences ($\Delta_{\max}$) specific to each EM's clinical context, expressed on the primary outcome scale.\cite{pearl2011}
\item \textbf{Sensitivity analysis}: Because the calibration depends on the CATE sensitivity parameter $L$, which may be uncertain, the framework naturally accommodates sensitivity analysis over $L$, providing a richer evidence base for decision-making than a single binary test.
\end{enumerate}

The remainder of this paper is organized as follows. Section~\ref{sec:methods} presents the methodological framework. Section~\ref{sec:simulation} describes a comprehensive simulation study. Section~\ref{sec:application} illustrates application to an MRCT dataset. Section~\ref{sec:discussion} discusses implications, limitations, and future directions.

%==============================================================================
\section{Methods}\label{sec:methods}
%==============================================================================

\subsection{The nABCD Metric}\label{sec:nabcd_metric}

An effect modifier (EM) is a baseline patient characteristic for which the treatment effect varies across subgroups. Formally, let the conditional average treatment effect (CATE) be denoted $\tau(x) = E[Y(1) - Y(0) \mid X = x]$, where $X$ is the effect modifier. When this function is non-constant, the average treatment effect observed in region $r$ depends on the distribution $F_r$ of the EM in that region:
\begin{equation}
\bar{\tau}_r = \int \tau(x) \, dF_r(x).
\label{eq:regional_ate}
\end{equation}

To formalize the relationship between distributional differences and treatment effect heterogeneity, let the CATE function be bounded with Lipschitz constant $L$. The difference in regional average treatment effects can be bounded by:
\begin{equation}
|\bar{\tau}_1 - \bar{\tau}_2| \leq L \cdot W_1(F_1, F_2),
\label{eq:heterogeneity_bound}
\end{equation}
where $W_1(F_1, F_2)$ denotes the Wasserstein-1 distance between EM distributions in regions 1 and 2.

The Wasserstein-1 distance (also known as the Earth Mover's Distance) between two cumulative distribution functions $F$ and $G$ is defined as:\cite{villani2009}
\begin{equation}
W_1(F, G) = \int_{-\infty}^{\infty} |F(x) - G(x)| \, dx.
\label{eq:wasserstein}
\end{equation}

Geometrically, this equals the total area between the two CDFs (Figure~\ref{fig:nabcd_definition}). Unlike the standardized mean difference, the Wasserstein distance responds to changes in variance, skewness, and other distributional features.\cite{panaretos2019}

\begin{figure}[t]
\centerline{\includegraphics[width=\textwidth]{fig2_nabcd_definition.pdf}}
\caption{nABCD as the area between cumulative distribution functions. The shaded region represents the Wasserstein-1 distance $W_1(F_1, F_2)$, which equals the total area between the two CDFs. nABCD normalizes this area by twice the pooled IQR to achieve scale-free interpretation.\label{fig:nabcd_definition}}
\end{figure}

The \textbf{normalized Area Between Cumulative Distributions (nABCD)} is defined as the Wasserstein-1 distance normalized by twice the pooled interquartile range:
\begin{equation}
\text{nABCD}(F_1, F_2) = \frac{W_1(F_1, F_2)}{2 \cdot \text{IQR}_{\text{pooled}}},
\label{eq:nabcd}
\end{equation}
where the pooled IQR is computed from the combined sample. The IQR-based normalization enables scale-free interpretation, is resistant to outliers, and expresses distributional differences in units of spread.

\begin{proposition}\label{prop:boundedness}
\textup{(Boundedness).} For distributions with finite IQR, $\text{nABCD} \geq 0$, with equality if and only if $F_1 = F_2$.
\end{proposition}

\begin{proposition}\label{prop:heterogeneity}
\textup{(Connection to heterogeneity).} If the CATE function has Lipschitz constant $L$, then
\begin{equation}
|\bar{\tau}_1 - \bar{\tau}_2| \leq 2L \cdot \text{IQR}_{\textup{pooled}} \cdot \text{nABCD}(F_1, F_2).
\label{eq:heterogeneity_nabcd}
\end{equation}
\end{proposition}

\begin{proof}
Substituting (\ref{eq:nabcd}) into (\ref{eq:heterogeneity_bound}) yields $|\bar{\tau}_1 - \bar{\tau}_2| \leq L \cdot W_1(F_1, F_2) = L \cdot 2 \cdot \text{IQR}_{\text{pooled}} \cdot \text{nABCD}(F_1, F_2) = 2L \cdot \text{IQR}_{\text{pooled}} \cdot \text{nABCD}(F_1, F_2)$.
\end{proof}

\subsection{Estimation}\label{sec:estimation}

Given samples $\{X_{1,i}\}_{i=1}^{n_1}$ from region 1 and $\{X_{2,j}\}_{j=1}^{n_2}$ from region 2, nABCD is estimated using empirical distribution functions:
\begin{equation}
\widehat{\text{nABCD}} = \frac{\sum_{k=1}^{n_1+n_2-1} |\hat{F}_1(x_{(k)}) - \hat{F}_2(x_{(k)})| \cdot (x_{(k+1)} - x_{(k)})}{2 \cdot \widehat{\text{IQR}}_{\text{pooled}}},
\label{eq:estimator}
\end{equation}
where $x_{(1)} < \cdots < x_{(n_1+n_2)}$ are the combined order statistics.

\textbf{Computational complexity}: $O((n_1 + n_2) \log(n_1 + n_2))$, dominated by sorting.

We employ the nonparametric percentile bootstrap for inference\cite{delbarrio1999,sommerfeld2018} with $B = 2{,}000$ replicates.

\subsection{Interpretation and Clinical Calibration}\label{sec:inference}

A central feature of nABCD is its connection to treatment effect heterogeneity through Proposition~\ref{prop:heterogeneity}. This connection provides the basis for a clinically grounded interpretation framework rather than reliance on fixed thresholds alone.

\subsubsection{Clinical Calibration via the Heterogeneity Bound}

From equation~(\ref{eq:heterogeneity_nabcd}), the maximum potential difference in regional average treatment effects attributable to EM distributional differences is:
\begin{equation}
\Delta_{\max} = 2L \cdot \text{IQR}_{\text{pooled}} \cdot \text{nABCD}(F_1, F_2),
\label{eq:delta_max}
\end{equation}
where $L$ is the Lipschitz constant of the CATE function $\tau(x)$ with respect to the EM, reflecting the clinical sensitivity of treatment effect to that EM. This use of $L$ as a sensitivity parameter follows the framework proposed by Armstrong and Koles\'{a}r,\cite{armstrong2021} who recommended reporting confidence intervals for a range of plausible Lipschitz constants. For a given EM, $L$ can be estimated from prior knowledge, pilot data, or published subgroup analyses.

The clinical calibration procedure is as follows:
\begin{enumerate}[1.]
\item Identify candidate EMs and compute nABCD with bootstrap CIs for each EM across region pairs.
\item For each EM, estimate or bound $L$ from prior knowledge (e.g., subgroup analyses showing treatment effect varies by $\Delta\tau$ per unit change in the EM, giving $L \approx \Delta\tau / \Delta x$).
\item Compute $\Delta_{\max}$ using equation~(\ref{eq:delta_max}). This represents the worst-case treatment effect difference attributable to the distributional difference.
\item Derive the bootstrap CI for $\Delta_{\max}$ from the nABCD confidence interval: $[\Delta_{\max,L},\, \Delta_{\max,U}] = 2L \cdot \text{IQR}_{\text{pooled}} \cdot [\text{nABCD}_{L},\, \text{nABCD}_{U}]$. This expresses inferential uncertainty directly on the clinical scale.
\item Report $\Delta_{\max}$ and its CI alongside the clinical context---for example, the overall treatment effect size, the non-inferiority margin, or the minimal clinically important difference. This information enables trial designers and regulatory scientists to exercise clinical judgment about pooling, considering the totality of evidence rather than a binary accept/reject decision.
\end{enumerate}

This estimation-centered approach deliberately avoids forcing pooling decisions into a binary hypothesis testing framework. The rationale is threefold. First, the ICH E17 guideline describes ``similar enough'' as inherently context-dependent, and reducing this judgment to a rejection threshold risks oversimplification. Second, the uncertainty in $L$ means that $\Delta_{\max}$ itself is subject to sensitivity analysis (Section~\ref{sec:application}); a binary test cannot naturally accommodate this layered uncertainty. Third, consistent with recent calls to move beyond dichotomous statistical decisions,\cite{wasserstein2016} presenting $\Delta_{\max}$ with its CI provides richer information for regulatory deliberation than a p-value or a reject/fail-to-reject outcome.

When regulatory agencies require a formal decision rule, the estimation framework can be adapted: declare pooling acceptable if the upper bound of the 95\% CI for $\Delta_{\max}$ falls below a pre-specified clinical margin $\Delta_{\text{clin}}$. However, we recommend this as a supplementary rather than primary use of the nABCD framework.

\subsubsection{Reference Benchmarks}

When prior knowledge of $L$ is unavailable, the benchmarks in Table~\ref{tab:benchmarks} provide a convenience reference for initial assessment. These assume moderate CATE sensitivity and should be interpreted cautiously.

\begin{table}[ht]
\caption{Reference benchmarks for nABCD values when CATE sensitivity $L$ is unknown.\label{tab:benchmarks}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lll@{}}
\toprule
\textbf{nABCD Range} & \textbf{Interpretation} & \textbf{Suggested Action} \\
\midrule
$< 0.05$ & Negligible difference & Pooling broadly supportable \\
$0.05$--$0.15$ & Small difference & Pooling generally acceptable \\
$0.15$--$0.30$ & Moderate difference & Proceed with clinical calibration \\
$> 0.30$ & Large difference & Clinical calibration essential \\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item These benchmarks are convenience references assuming moderate CATE sensitivity. Actual pooling decisions should use clinical calibration (equation~\ref{eq:delta_max}) whenever possible.
\end{tablenotes}
\end{table}

%==============================================================================
\section{Simulation Study}\label{sec:simulation}
%==============================================================================

We conducted simulation studies to evaluate the estimation properties of the nABCD estimator: bias, variability, and coverage probability of bootstrap confidence intervals. These properties are essential for the clinical calibration framework, as reliable estimation of nABCD directly determines the quality of $\Delta_{\max}$ estimates. We assessed performance across a range of scenarios relevant to MRCT applications.

\subsection{Simulation Design}\label{sec:sim_design}

\subsubsection{Scenarios}

We designed two sets of scenarios. First, systematic scenarios for methodological validation examined controlled distributional differences: null (identical distributions), location shifts of 0.2, 0.5, and 1.0 standard deviations, scale difference (1.5-fold increase in standard deviation), and shape difference (Normal versus Gamma). Table~\ref{tab:scenarios} summarizes these scenarios with their true nABCD values.

\begin{table}[ht]
\caption{Systematic simulation scenarios.\label{tab:scenarios}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lllll@{}}
\toprule
\textbf{ID} & \textbf{Description} & \textbf{Distribution 1} & \textbf{Distribution 2} & \textbf{True nABCD} \\
\midrule
S01 & Null & $N(50, 10^2)$ & $N(50, 10^2)$ & 0.000 \\
S03 & Location 0.2$\sigma$ & $N(50, 10^2)$ & $N(52, 10^2)$ & 0.074 \\
S04 & Location 0.5$\sigma$ & $N(50, 10^2)$ & $N(55, 10^2)$ & 0.186 \\
S05 & Location 1.0$\sigma$ & $N(50, 10^2)$ & $N(60, 10^2)$ & 0.372 \\
S06 & Scale 1.5$\times$ & $N(50, 10^2)$ & $N(50, 15^2)$ & 0.148 \\
S08 & Shape & $N(50, 10^2)$ & Gamma$(25, 0.5)$ & 0.067 \\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item The Gamma distribution in S08 has shape parameter 25 and rate 0.5, yielding mean 50 and standard deviation 10.
\end{tablenotes}
\end{table}

Second, realistic clinical scenarios examined effect modifiers commonly encountered in MRCTs: BMI comparing Japan ($\mu=23$, $\sigma=3$) versus US ($\mu=28$, $\sigma=5$), age in elderly trials comparing Japan ($\mu=72$, $\sigma=8$) versus US ($\mu=68$, $\sigma=10$), eGFR in CKD populations, and HbA1c in diabetes trials. These parameters were informed by published literature on regional differences in patient characteristics.\cite{sai2021}

\subsubsection{Simulation Parameters}

For each scenario, we generated samples of size $n = 50$, 100, and 200 per region, reflecting sample sizes typical in MRCT regional subgroups. We performed 10{,}000 replications per scenario--sample size combination to ensure stable estimates of operating characteristics, with Monte Carlo standard errors below 0.005 for all reported proportions. Bootstrap confidence intervals were computed using $B = 2{,}000$ resamples. All simulations were conducted in R version 4.3.3.

\subsubsection{Evaluation Metrics}

Consistent with the estimation-centered framework, we evaluated:
\begin{enumerate}[1.]
\item \textbf{Bias}: $\text{Mean}(\widehat{\text{nABCD}}) - \text{true nABCD}$
\item \textbf{Root mean squared error (RMSE)}: $\sqrt{\text{Mean}[(\widehat{\text{nABCD}} - \text{true nABCD})^2]}$
\item \textbf{Coverage probability}: Proportion of 95\% bootstrap CIs containing the true value
\item \textbf{CI width}: Mean width of bootstrap CIs, reflecting estimation precision
\end{enumerate}

\subsection{Results}\label{sec:sim_results}

\subsubsection{Point Estimation and Coverage}

Table~\ref{tab:bias} presents the bias of the nABCD estimator across scenarios and sample sizes. The estimator showed positive bias under the null hypothesis (S01), with bias decreasing from 0.093 at $n=50$ to 0.046 at $n=200$. This positive bias is attributable to the non-negative nature of the Wasserstein distance: even when true nABCD equals zero, sampling variability produces positive estimates.

\begin{table}[ht]
\caption{Bias of nABCD estimator by scenario and sample size.\label{tab:bias}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lcccc@{}}
\toprule
\textbf{Scenario} & \textbf{True nABCD} & $\boldsymbol{n=50}$ & $\boldsymbol{n=100}$ & $\boldsymbol{n=200}$ \\
\midrule
S01 (Null) & 0.000 & 0.093 & 0.066 & 0.046 \\
S03 (0.2$\sigma$) & 0.074 & 0.040 & 0.019 & 0.006 \\
S04 (0.5$\sigma$) & 0.186 & 0.002 & $-0.002$ & $-0.004$ \\
S05 (1.0$\sigma$) & 0.372 & $-0.035$ & $-0.042$ & $-0.044$ \\
S06 (Scale) & 0.148 & 0.001 & $-0.014$ & $-0.018$ \\
S08 (Shape) & 0.067 & 0.033 & 0.003 & $-0.016$ \\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item Bias is defined as $\text{Mean}(\widehat{\text{nABCD}}) - \text{true nABCD}$. Results based on 10{,}000 replications with $B = 2{,}000$ bootstrap resamples.
\end{tablenotes}
\end{table}

For non-null scenarios excluding S05, bias was less than 0.02 in absolute value at $n \geq 100$, indicating satisfactory point estimation performance at practical sample sizes. For S05 (1.0$\sigma$ location shift), negative bias of approximately $-0.04$ persisted across all sample sizes, reflecting the bounded nature of nABCD near its theoretical upper range (Figure~\ref{fig:bias}).

\begin{figure}[t]
\centerline{\includegraphics[width=\textwidth]{fig3_bias.pdf}}
\caption{Bias of nABCD estimator by scenario and sample size. Horizontal dashed lines indicate $\pm 0.02$ bias threshold. Bias is less than 0.02 for non-null scenarios at $n \geq 100$.\label{fig:bias}}
\end{figure}

Table~\ref{tab:coverage} presents coverage probabilities of the 95\% bootstrap confidence intervals. For $n \geq 100$, coverage was within 0.93--0.98 for most scenarios (S04, S06, S08), with moderate undercoverage for S03 at $n = 100$ (0.896). S05 showed progressive undercoverage with increasing $n$ (0.852 at $n = 100$, 0.732 at $n = 200$), attributable to the persistent negative bias under large distributional differences. At $n = 50$, undercoverage was more pronounced, particularly for S08 (0.538) and S03 (0.674), indicating that this sample size is insufficient for reliable inference.

\begin{table}[ht]
\caption{Coverage probability of 95\% bootstrap confidence intervals.\label{tab:coverage}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lccc@{}}
\toprule
\textbf{Scenario} & $\boldsymbol{n=50}$ & $\boldsymbol{n=100}$ & $\boldsymbol{n=200}$ \\
\midrule
S03 (0.2$\sigma$) & 0.674 & 0.896 & 0.950 \\
S04 (0.5$\sigma$) & 0.952 & 0.952 & 0.936 \\
S05 (1.0$\sigma$) & 0.918 & 0.852 & 0.732 \\
S06 (Scale) & 0.958 & 0.978 & 0.950 \\
S08 (Shape) & 0.538 & 0.950 & 1.000 \\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item Coverage under S01 (Null) is not reported because the true value of 0 lies at the boundary of the parameter space.
\item For S05 (large effect), coverage decreased at larger sample sizes due to increased precision revealing the small negative bias.
\end{tablenotes}
\end{table}

\subsubsection{Estimation Precision}

Figure~\ref{fig:estimation_quality} summarizes the estimation quality across scenarios and sample sizes, presenting both coverage probabilities and mean CI widths.

\begin{figure*}[t]
\centerline{\includegraphics[width=\textwidth]{fig4_estimation_quality.pdf}}
\caption{Estimation quality of nABCD bootstrap inference. Panel~(A) shows coverage probability of 95\% bootstrap confidence intervals; dashed and dotted lines indicate the nominal 0.95 and minimum acceptable 0.90 levels. Panel~(B) shows mean CI width in nABCD units. Coverage exceeds 0.90 for most scenarios at $n \geq 100$; CI width narrows consistently with increasing $n$.\label{fig:estimation_quality}}
\end{figure*}

Table~\ref{tab:precision} presents the RMSE and mean CI width across scenarios. RMSE decreased consistently with increasing $n$, reaching values below 0.05 for all scenarios at $n = 200$. Mean CI width narrowed proportionally, with CIs at $n = 100$ typically spanning 0.10--0.16 in nABCD units. In the clinical calibration framework, this CI width propagates to $\Delta_{\max}$: for example, with $L = 0.3$ and IQR = 1.5, a CI width of 0.14 in nABCD corresponds to a CI width of $2 \times 0.3 \times 1.5 \times 0.14 = 0.13$\% HbA1c---a level of precision sufficient for meaningful clinical calibration.

\begin{table}[ht]
\caption{RMSE and mean CI width by scenario and sample size.\label{tab:precision}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lcccccc@{}}
\toprule
& \multicolumn{3}{c}{\textbf{RMSE}} & \multicolumn{3}{c}{\textbf{Mean CI Width}} \\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}
\textbf{Scenario} & $\boldsymbol{n=50}$ & $\boldsymbol{n=100}$ & $\boldsymbol{n=200}$ & $\boldsymbol{n=50}$ & $\boldsymbol{n=100}$ & $\boldsymbol{n=200}$ \\
\midrule
S01 (Null) & 0.099 & 0.071 & 0.049 & 0.12 & 0.10 & 0.07 \\
S03 (0.2$\sigma$) & 0.063 & 0.041 & 0.032 & 0.16 & 0.14 & 0.12 \\
S04 (0.5$\sigma$) & 0.066 & 0.048 & 0.037 & 0.21 & 0.17 & 0.14 \\
S05 (1.0$\sigma$) & 0.072 & 0.061 & 0.053 & 0.22 & 0.16 & 0.11 \\
S06 (Scale) & 0.048 & 0.035 & 0.029 & 0.16 & 0.12 & 0.09 \\
S08 (Shape) & 0.051 & 0.023 & 0.024 & 0.13 & 0.09 & 0.07 \\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item CI width is defined as mean of (upper $-$ lower) across 10{,}000 replications.
\end{tablenotes}
\end{table}

Under the null hypothesis (S01), the positive bias produces CIs that are shifted upward from zero. At $n = 50$, the mean estimate was 0.093 with mean CI width 0.12; at $n = 200$, the mean estimate decreased to 0.046 with mean CI width 0.07. This bias is relevant for clinical calibration: when the true distributional difference is zero, the estimator will suggest a small positive $\Delta_{\max}$. Practitioners should be aware of this conservative tendency, particularly at smaller sample sizes.

\subsubsection{Comparison with Standardized Mean Difference}

Table~\ref{tab:smd} compares the sensitivity of nABCD and SMD to different types of distributional differences. While both metrics respond to location shifts, SMD is insensitive to differences in variance and shape---the very types of distributional differences that may drive treatment effect heterogeneity through non-linear CATE functions.

\begin{table}[ht]
\caption{Sensitivity comparison: nABCD versus SMD at $n=100$.\label{tab:smd}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lccc@{}}
\toprule
\textbf{Scenario} & \textbf{nABCD (mean $\pm$ SD)} & \textbf{SMD (mean $\pm$ SD)} & \textbf{Implication} \\
\midrule
S04 (Location) & $0.184 \pm 0.048$ & $0.50 \pm 0.14$ & Both detect \\
S06 (Scale only) & $0.134 \pm 0.032$ & $0.00 \pm 0.14$ & Only nABCD detects \\
S08 (Shape only) & $0.069 \pm 0.023$ & $0.00 \pm 0.14$ & Only nABCD detects \\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item SMD depends only on the difference in means, making it insensitive to differences in variance and distributional shape. nABCD captures the full distributional difference.
\end{tablenotes}
\end{table}

\begin{figure*}[t]
\centerline{\includegraphics[width=\textwidth]{fig5_smd_comparison.pdf}}
\caption{Comparison of nABCD and SMD across distributional difference types. nABCD responds to scale (S06) and shape (S08) differences where SMD remains near zero, demonstrating its advantage for full distributional comparison.\label{fig:smd}}
\end{figure*}

In summary, the simulation study demonstrates that the nABCD estimator provides reliable estimation with the following properties at sample sizes typical in MRCT regional subgroups:
\begin{enumerate}[1.]
\item \textbf{Bias}: Less than 0.02 for non-null scenarios at $n \geq 100$
\item \textbf{Coverage}: 0.89--0.98 at $n \geq 100$ for most scenarios
\item \textbf{Precision}: RMSE below 0.05 and CI width below 0.17 at $n \geq 100$
\item \textbf{Sensitivity}: Captures location, scale, and shape differences where SMD is limited to location only
\end{enumerate}

These estimation properties ensure that nABCD, when combined with the clinical calibration framework, provides $\Delta_{\max}$ estimates of sufficient quality for regulatory deliberation. We recommend $n \geq 100$ per region for reliable estimation and inference.

%==============================================================================
\section{Application}\label{sec:application}
%==============================================================================

\subsection{Example: Type 2 Diabetes MRCT}\label{sec:app_diabetes}

We illustrate the nABCD clinical calibration framework using a hypothetical MRCT in type 2 diabetes with three regions: Japan ($n = 150$), United States ($n = 200$), and European Union ($n = 180$). The primary endpoint was change in HbA1c (\%) at 24 weeks, with an overall treatment effect of $-0.8$\% and a pre-specified non-inferiority margin of $\Delta_{\text{clin}} = 0.4$\% HbA1c. Table~\ref{tab:baseline} presents baseline characteristics by region.

\begin{table}[ht]
\caption{Baseline characteristics by region in the hypothetical diabetes MRCT.\label{tab:baseline}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lccc@{}}
\toprule
\textbf{Characteristic} & \textbf{Japan ($n=150$)} & \textbf{US ($n=200$)} & \textbf{EU ($n=180$)} \\
\midrule
Age, mean (SD) & 62.3 (10.2) & 58.7 (11.5) & 60.1 (10.8) \\
BMI, mean (SD) & 24.8 (3.2) & 32.1 (5.8) & 29.4 (4.9) \\
HbA1c, mean (SD) & 7.6 (0.9) & 8.4 (1.3) & 8.1 (1.1) \\
\bottomrule
\end{tabular*}
\end{table}

Table~\ref{tab:nabcd_results} presents pairwise nABCD values with 95\% bootstrap CIs for the three candidate effect modifiers.

\begin{table}[ht]
\caption{Pairwise nABCD values with 95\% bootstrap confidence intervals.\label{tab:nabcd_results}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lccc@{}}
\toprule
\textbf{Effect Modifier} & \textbf{Japan vs.\ US} & \textbf{Japan vs.\ EU} & \textbf{US vs.\ EU} \\
\midrule
Age & 0.12 (0.07--0.18) & 0.08 (0.04--0.13) & 0.05 (0.02--0.09) \\
BMI & 0.51 (0.44--0.58) & 0.38 (0.31--0.45) & 0.18 (0.12--0.24) \\
HbA1c & 0.27 (0.20--0.34) & 0.19 (0.13--0.26) & 0.10 (0.05--0.16) \\
\bottomrule
\end{tabular*}
\end{table}

\begin{figure}[t]
\centerline{\includegraphics[width=\textwidth]{fig6_application.pdf}}
\caption{BMI distributions by region in the hypothetical diabetes MRCT. Japan shows substantially lower BMI compared to US and EU (nABCD = 0.51 for Japan--US). However, the clinical impact depends on BMI's role as an effect modifier, quantified through the heterogeneity bound $\Delta_{\max}$.}\label{fig:application}
\end{figure}

\subsubsection{Clinical Calibration}

The nABCD values alone do not determine pooling decisions. We apply the clinical calibration procedure from Section~\ref{sec:inference} to translate distributional differences into potential treatment effect heterogeneity.

\textbf{Step 1: Estimate CATE sensitivity $L$ for each EM.}
From published subgroup analyses in diabetes trials, we adopt the following estimates for the Lipschitz constant of the CATE function:
\begin{itemize}
\item \textbf{Age}: $L_{\text{age}} \approx 0.01$\% HbA1c per year. Subgroup analyses typically show modest age--treatment interactions, with treatment effect varying by approximately 0.1\% HbA1c per decade of age.
\item \textbf{BMI}: $L_{\text{BMI}} \approx 0.02$\% HbA1c per kg/m$^2$. A regression analysis of DPP-4 inhibitor efficacy estimated a BMI coefficient of $-0.02$ per kg/m$^2$ ($p = 0.024$) for the relationship between BMI and HbA1c reduction.\cite{kim2015}
\item \textbf{HbA1c}: $L_{\text{HbA1c}} \approx 0.3$\% HbA1c per \% HbA1c. Baseline HbA1c is the strongest effect modifier for most glucose-lowering therapies: meta-regression of 98 DPP-4 inhibitor trials estimated 0.4--0.5 percentage points greater HbA1c reduction per 1\% higher baseline,\cite{craddy2014} and a GLP-1 receptor agonist study estimated $\beta = -0.31$ per \% HbA1c after correcting for regression to the mean.\cite{jones2016}
\end{itemize}

\textbf{Step 2: Compute $\Delta_{\max}$ for the most discrepant region pair.}
Table~\ref{tab:calibration} presents the clinical calibration for the Japan--US comparison, which showed the largest nABCD values across all EMs.

\begin{table}[ht]
\caption{Clinical calibration of nABCD for the Japan--US comparison.\label{tab:calibration}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lccccc@{}}
\toprule
\textbf{EM} & \textbf{nABCD} & $\boldsymbol{L}$ & \textbf{IQR\textsubscript{pooled}} & $\boldsymbol{\Delta_{\max}}$ & \textbf{vs.\ $\Delta_{\text{clin}}$} \\
\midrule
Age & 0.12 & 0.01 & 14.2 yr & 0.03\% & $\ll 0.4$\% \\
BMI & 0.51 & 0.02 & 7.8 kg/m$^2$ & 0.16\% & $< 0.4$\% \\
HbA1c & 0.27 & 0.30 & 1.5\% & 0.24\% & $< 0.4$\% \\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item $\Delta_{\max} = 2 \times L \times \text{IQR}_{\text{pooled}} \times \text{nABCD}$ (equation~\ref{eq:delta_max}). $\Delta_{\text{clin}} = 0.4$\% HbA1c (non-inferiority margin).
\end{tablenotes}
\end{table}

\textbf{Step 3: Interpret $\Delta_{\max}$ in clinical context.}

The calibration reveals a nuanced picture that illustrates why clinical context, not nABCD alone, must drive interpretation:
\begin{itemize}
\item \textbf{Age} (nABCD = 0.12): $\Delta_{\max} = 0.03$\%, representing less than 4\% of the overall treatment effect ($-0.8$\% HbA1c) and less than 8\% of the non-inferiority margin. Age is a weak effect modifier for this drug class, and the distributional difference between regions translates to negligible potential heterogeneity.
\item \textbf{BMI} (nABCD = 0.51): Despite the large distributional difference, $\Delta_{\max} = 0.16$\%, or 20\% of the overall treatment effect. BMI's low CATE sensitivity ($L = 0.02$) means that even substantial distributional differences have limited impact on treatment effect heterogeneity. Note that reference benchmarks alone would suggest ``large difference''---an assessment that overlooks the weak relationship between BMI and treatment response for this drug class.
\item \textbf{HbA1c} (nABCD = 0.27): $\Delta_{\max} = 0.24$\%, reaching 30\% of the overall treatment effect and 60\% of the non-inferiority margin. Although the nABCD is smaller than for BMI, baseline HbA1c's strong CATE sensitivity ($L = 0.30$) means the moderate distributional difference carries greater clinical weight. This comparison warrants careful deliberation.
\end{itemize}

This example demonstrates that \textbf{the clinical meaning of nABCD depends on the EM's role as an effect modifier}. A large nABCD for a weak EM (BMI, $L = 0.02$) may be less consequential than a moderate nABCD for a strong EM (HbA1c, $L = 0.30$). When $L$ is uncertain, sensitivity analysis over plausible values is essential. Table~\ref{tab:sensitivity} illustrates this for baseline HbA1c.

\begin{table}[ht]
\caption{Sensitivity analysis: $\Delta_{\max}$ as a function of assumed CATE sensitivity $L$ for baseline HbA1c (Japan vs.\ US, nABCD = 0.27, IQR = 1.5\%).\label{tab:sensitivity}}
\begin{tabular*}{\textwidth}{@{\extracolsep\fill}lcc@{}}
\toprule
$\boldsymbol{L}$ \textbf{(assumed)} & $\boldsymbol{\Delta_{\max}}$ & \textbf{as \% of treatment effect} \\
\midrule
0.10 & 0.08\% & 10\% \\
0.20 & 0.16\% & 20\% \\
0.30 & 0.24\% & 30\% \\
0.40 & 0.32\% & 40\% \\
0.50 & 0.41\% & 51\% \\
\bottomrule
\end{tabular*}
\begin{tablenotes}
\item Overall treatment effect: $-0.8$\% HbA1c. The value $L^* = \Delta_{\text{clin}} / (2 \cdot \text{IQR} \cdot \text{nABCD}) = 0.49$ represents the CATE sensitivity at which $\Delta_{\max}$ equals the non-inferiority margin of 0.4\%.
\end{tablenotes}
\end{table}

The sensitivity analysis provides trial designers and regulators with a transparent view: for this EM and region pair, at what level of CATE sensitivity does the distributional difference begin to matter clinically? This framing supports informed deliberation rather than a binary decision, consistent with the ICH E17 principle that ``similar enough'' requires contextual judgment.

The analysis illustrates that nABCD serves as a \textbf{measuring instrument} for distributional distance, while the \textbf{clinical judgment} of whether that distance matters requires integration with domain knowledge about the EM's CATE sensitivity. The role of the statistician is to provide $\Delta_{\max}$ and its uncertainty; the role of the clinical team is to evaluate that information against the therapeutic context.

%==============================================================================
\section{Discussion}\label{sec:discussion}
%==============================================================================

We developed and validated nABCD, a normalized metric for comparing effect modifier distributions in MRCTs. Our contributions include: (1)~a principled metric combining Wasserstein-1 distance with IQR normalization; (2)~a theoretical framework connecting nABCD to treatment effect heterogeneity through the heterogeneity bound; (3)~a clinical calibration procedure that translates nABCD values into context-specific assessments using CATE sensitivity; and (4)~rigorous validation through simulation.

\subsection{Implications for Practice}\label{sec:implications}

The nABCD metric addresses limitations of current approaches. Compared to SMD, nABCD captures full distributional differences including variance and shape. Our simulation demonstrated that nABCD captured scale differences (S06) and shape differences (S08) where SMD estimates remained near zero. Compared to the KS statistic, nABCD provides a direct connection to treatment effect heterogeneity through the heterogeneity bound (equation~\ref{eq:delta_max}), enabling clinical calibration rather than purely statistical assessment. Compared to visual inspection, nABCD is objective and reproducible.

The clinical calibration procedure introduced in Section~\ref{sec:inference} represents a departure from fixed-threshold approaches. Cohen's $d$ benchmarks (small = 0.2, medium = 0.5, large = 0.8) have been widely criticized for context-free application, and we deliberately avoid this pattern. Instead, the heterogeneity bound provides a principled mechanism to translate nABCD into clinically meaningful units. This approach respects the ICH E17 principle that ``similar enough'' is context-dependent: the same nABCD value may support pooling for one EM (where CATE sensitivity is low) but warrant separate analysis for another (where CATE sensitivity is high), as demonstrated in Section~\ref{sec:application}. This connection draws on transportability theory\cite{pearl2011,bareinboim2016} to relate distributional distance to potential treatment effect heterogeneity.

Based on our findings, we offer the following recommendations for practitioners:
\begin{enumerate}[1.]
\item Compute nABCD with bootstrap CIs ($n \geq 100$ per region) for each candidate EM across region pairs.
\item Translate nABCD into $\Delta_{\max}$ and its CI on the clinical outcome scale using equation~(\ref{eq:delta_max}), incorporating prior knowledge or estimates of CATE sensitivity $L$.
\item Report $\Delta_{\max}$ and its CI alongside the overall treatment effect, non-inferiority margin, or other clinically relevant benchmarks to support informed deliberation about pooling.
\item Conduct sensitivity analyses over plausible values of $L$ when prior knowledge is uncertain (Table~\ref{tab:sensitivity}).
\item When $L$ cannot be estimated, use the reference benchmarks in Table~\ref{tab:benchmarks} as initial guidance, recognizing that clinical calibration provides a more rigorous basis for decision-making.
\end{enumerate}

\subsection{Limitations and Future Directions}\label{sec:limitations}

Several limitations should be acknowledged:
\begin{enumerate}[1.]
\item The current formulation applies to continuous EMs only; extensions to categorical or mixed-type EMs require further development.
\item nABCD evaluates each EM separately rather than jointly; a multivariate extension would address potential confounding among EMs.
\item Positive bias under the null at small sample sizes ($n < 100$) can inflate nABCD estimates; we recommend $n \geq 100$ per region for reliable point estimation and confidence intervals.
\item The clinical calibration requires estimation of CATE sensitivity $L$, which may not always be available from prior data. Reference benchmarks are provided as a fallback but should not replace context-specific calibration.
\end{enumerate}

Future work should address multivariate extensions, bias correction methods for small samples, and empirical calibration of CATE sensitivity parameters using real MRCT data. Methods for estimating $L$ from historical trial databases would strengthen the clinical calibration framework. The nABCD framework could also be extended to longitudinal EM profiles, enabling dynamic assessment of distributional similarity over time.

\subsection{Conclusion}\label{sec:conclusion}

nABCD fills a methodological gap in ICH E17 implementation by providing a principled framework for assessing distributional similarity. Rather than reducing ``similar enough'' to a fixed threshold, the clinical calibration procedure translates distributional differences into context-specific assessments of potential treatment effect heterogeneity, enabling evidence-based and clinically grounded pooling decisions. Open-source R code is available to facilitate adoption.

%==============================================================================
% Back matter
%==============================================================================

\bmsection*{Author contributions}

[Author 1] conceived the research question and led the project. [Author 2] developed the mathematical framework and conducted the simulation study. [Author 3] contributed to the application example and manuscript preparation. All authors reviewed and approved the final manuscript.

\bmsection*{Acknowledgments}

The authors thank [colleagues] for helpful discussions on ICH E17 implementation.

\bmsection*{Financial disclosure}

None reported.

\bmsection*{Conflict of interest}

The authors declare no potential conflict of interests.

\bmsection*{Data availability statement}

R code for computing nABCD and reproducing the simulation study is available at [repository URL].

\bibliography{nABCD_wiley}

\bmsection*{Supporting information}

Additional supporting information may be found in the online version of the article at the publisher's website. Supporting materials include: complete R code for nABCD computation, simulation scripts, and additional figures for realistic clinical scenarios.

%==============================================================================
\appendix
%==============================================================================

\bmsection{Proofs and Mathematical Details\label{app:proofs}}

\bmsubsection{Proof of Proposition~\ref{prop:boundedness}\label{app:proof1}}

Non-negativity follows directly from the non-negativity of the Wasserstein-1 distance: $W_1(F_1, F_2) = \int |F_1(x) - F_2(x)| \, dx \geq 0$, with equality if and only if $F_1(x) = F_2(x)$ for all $x$. Since $\text{IQR}_{\text{pooled}} > 0$ for non-degenerate distributions, the ratio $\text{nABCD} = W_1 / (2 \cdot \text{IQR}_{\text{pooled}}) \geq 0$.

\bmsubsection{Asymptotic Properties\label{app:asymptotic}}

Under standard regularity conditions, the empirical Wasserstein-1 distance $W_1(\hat{F}_1, \hat{F}_2)$ is a consistent estimator of $W_1(F_1, F_2)$.\cite{delbarrio1999} Combined with the consistency of the empirical IQR, $\widehat{\text{nABCD}}$ is a consistent estimator of $\text{nABCD}(F_1, F_2)$.

The bootstrap provides valid inference for the Wasserstein distance under mild conditions.\cite{sommerfeld2018} The percentile bootstrap confidence interval achieves asymptotically correct coverage for non-degenerate distributions.

\bmsection{R Code for nABCD Computation\label{app:rcode}}

\begin{lstlisting}[caption={R function for computing nABCD with bootstrap confidence intervals.},label=lst:nabcd,basicstyle=\fontsize{8}{10}\selectfont\ttfamily]
compute_nABCD <- function(x1, x2) {
  pooled <- c(x1, x2)
  iqr_pooled <- IQR(pooled)
  if (iqr_pooled == 0) return(NA)
  all_vals <- sort(unique(pooled))
  F1 <- ecdf(x1); F2 <- ecdf(x2)
  w1 <- sum(diff(all_vals) *
    abs(F1(all_vals[-length(all_vals)]) -
        F2(all_vals[-length(all_vals)])))
  w1 / (2 * iqr_pooled)
}

nABCD_bootstrap <- function(x1, x2,
    B = 2000, conf = 0.95) {
  obs <- compute_nABCD(x1, x2)
  boot_vals <- replicate(B, {
    b1 <- sample(x1, replace = TRUE)
    b2 <- sample(x2, replace = TRUE)
    compute_nABCD(b1, b2)
  })
  alpha <- 1 - conf
  ci <- quantile(boot_vals,
    c(alpha/2, 1 - alpha/2), na.rm = TRUE)
  list(estimate = obs,
       ci_lower = ci[1], ci_upper = ci[2])
}
\end{lstlisting}

\end{document}
